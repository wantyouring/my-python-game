랜덤평균은 약 10정도

model1
frame skip 5단위(5
64 64 3 dense layer.
=> 학습 잘 안됨

model2
frame skip 4단위
256 128 3 dense layer
=> 2400epi까지 학습 잘 안됨.
avg qmax가 일정 이상 안올라감. 더 큰 layer써보기.

lr늘리고 update_target_rate줄여 다시 학습해보기.
랜덤으로 떨어지는 똥의 위치를 특정 n개 위치에서만 떨어지게끔 환경 바꾸기!

model3
1024 512 3 dense layer로 학습
=> 3000epi까지 학습해놓은거 이어서 학습시켜보기. 현재까지는 그냥 random보다 살짝 좋은정도...lr *1/10 더 줄여보기.

model4
frame skip 없이 학습시켜보자.
256 256 3 dense layer
=> model3보다 더 안됨.

model3이어서 학습중
=> 학습 잘 되지 않는다.
환경을 좀 더 단순화 시켜보기. 시작 y위치도 일정한 몇 개 위치중 랜덤하게 떨어지게끔. 

model5
시작 똥 y위치도 20개의 위치중 10개 위치 고르기. ddong_speed도 시작 y위치간격과 동일하게.
=> 학습 잘 안됨.

model6
시작 똥 x,y위치 모두 고정한 환경에서 학습되는지 테스트.
64 64 3 dense layer
dx 48로 크게 움직이게.(조금씩 여러 action이 모여 reward에 영향 미칠것같음), frame skip 없이.
=> 여기서 계속 파라미터, dx(24 -> 48) 등 바꿔가며 시도중.
lr 많이 줄여 해보기. 정밀한 fitting.

32 32 3 dense layer는 학습 안됨.

64 64 layer에서 55000epi쯤에서 학습완료됨. but play시 잘 안됨. 이어서 더 학습시켜보기. 학습완료조건 없이.

=> 학습 잘 안되었음.


model7
똥 갯수 조금 줄여보기.
학습중@@@@@@@

model8
layer 층을 여러개로 늘려보기

cnn사용해야하나??